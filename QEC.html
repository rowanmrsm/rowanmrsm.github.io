<!doctype html>
<html>
<head>
<title>Quantum Error Correction</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Righteous">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mallanna">
<link rel = "stylesheet" href = "qecstyle.css"> 

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
</head>
<body>
<ul class = "menu">
<li class = "link"><a href = "index.html">Home</a></li>
<li class = "link"><a href = "classicalECC.html">Classical Error Correcting Codes</a></li>
<li class = "link"><a href = "QuantComputers.html">Quantum Computers</a></li>
<li class = "link active"><a href = "QEC.html">Quantum ECC</a></li>
<li class = "link"><a href = "Faulttolerance.html">Fault Tolerance</a></li>
<li class = "link"><a href = "about.html">About, Docs and References</a></li>
</ul>

<h1>Quantum Error Correcting Codes</h1>
<p>Quantum error correction protocols are very necessary – there are a lot of potential noise sources at every stage of the computation, and a result known as the No-Cloning theorem means that data can’t just be backed up. This theorem says that an arbitrary unknown quantum state cannot be perfectly duplicated, and so a copy of the data cannot be made in case an error occurs. 
There are also far more types of error that can affect the data – a $|1\rangle$ could be changed to a $|0\rangle$, but it could also be moved to any other point on the Bloch sphere. Most commonly, the main errors that an error correction protocol considers are based on the Pauli group: the transformations given by the following matrices and their multiplications by -1, +i and -i, which are orthogonal to each other: 
$$X=\begin{bmatrix}0&1\\1&0\end{bmatrix},\ \ Y=\begin{bmatrix}0&-i\\i&0\end{bmatrix},\ \ Z=\begin{bmatrix}1&0\\0&-1\end{bmatrix}$$
The X matrix performs a NOT gate, referred to as a bit-flip error, and the Z matrix changes the $|1\rangle$ component to $-|1\rangle$, so it is known as a phase-flip error. Working with a system of coupled qubits, an error is the tensor product of various combinations of these matrices and the identity matrix: if a communication channel changes the first qubit in a three-qubit block between $|0\rangle$ and $|1\rangle$ and the third between $|1\rangle$ and $-|1\rangle$ the error is written as $X\otimes\ I\otimes\ Z$. They are referred to as error operators and typically written $E_i$. Some basic assumptions are usually made about the nature of these errors to make them easier to work with:
<ul>
	<li>Independence – whether or not an error happens on one qubit doesn’t affect how likely it is an error occurs on the next</li>
	<li>Identical distribution – the likelihood of each Pauli matrix error occurring is the same and the overall likelihood of an error is the same for each qubit</li>
</ul>
<p>The communication channel which causes these errors is known as a depolarisation channel, which has a certain probability of changing a qubit to a state maximising the Von Neumann entropy which describes how uncertain the state of a quantum system is before it is measured. 
Other types of error are also possible – for example amplitude damping, which reduces the probability of the system being in the state $|1\rangle$. This is often due to effects such as an ion trap qubit releases a photon and returns to the ground state rather than the excited state. However, these types of errors are not as simple to deal with and are not so commonly explored.</p>

<p>Encoding a quantum computation frequently uses a stabiliser code, which uses algebraic constructions to develop code words. A quantum code is a map from $H_2^k$, the product of k two-state Hilbert spaces to $H_2^n$, the product of n and therefore uses n qubits to represent what was stored on the k initial qubits. It is common to use the Pauli matrices to create a basis for the spaces which lets the couplings of k and n  qubits be represented by tensor products of these matrices in the same way as the errors. There are typically some algebraic constraints in picking exactly which matrices to use, which will become clear as we investigate the construction of stabiliser codes.</p>
<p>There are k basis vectors in the code space $C$, so it is a k dimensional subspace of $H_2^n$. Consider its stabiliser S, which is generated by $n-k$ elements of  $H_2^n$ which will be written as $g_i$ for $i$ between 1 and $n-k$. Each generator has an eigenvalue of +1 or -1, and the code vectors in particular are all eigenvectors of the generators with eigenvalue +1. More generally, if the eigenvalue which a vector gives for $g_i$ is $(-1)^{l_i}$, we associate it with the string $l = l_1l_2\ldots l_{n-k}$ and create subsets of the vectors which are all associated with the same string. These are referred to as $C(l)$.</p> 
<p>An error will map code vectors to vectors in one of the $C(l)$, depending on how the operator interacts with each generator – if it commutes then $l_i = 0$ and if it anti-commutes then $l_i = 1$. This lets the syndrome of the error be defined as the string associated to $C(l)$. To find the syndrome, a parity check matrix is used like those from classical codes, with the generators of the stabiliser. As $g_ic = c$ for all the code vectors, using them to construct a matrix results in a matrix which returns the vector $\begin{bmatrix}(-1)^{l_1}\\ \vdots\\(-1)^{l_{n-k}}\end{bmatrix}$, which can be easily used to find the relevant code space and the errors which are associated with it. </p>
<p>This construction indicates one constraint for choosing generators – every error needs to anti-commute with at least one so that the code vector is moved to a different subset. It may not be possible, or even necessary, to construct the stabiliser so that every error has a unique syndrome: just like a classical channel, it is far more likely that certain errors will occur than others, so correcting methods faced with multiple potential errors assume the most likely one has occurred. Other conditions needed for a good code are orthogonality, and indistinguishability. Orthogonality requires $\langle i|E_a^{\dagger} E_b│j\rangle$  to be 0 for every pair of code states and every pair of errors. Indistuiguishability requires $\langle\ i|E_a^{\dagger} E_b│i\rangle  = \langle j│E_a^{\dagger} E_b│j\rangle$  for each generator, which prevents any environmental interference from telling generators apart and collapsing the superposition. To make choosing a generating set easier, if a code is able to correct a spanning subset of the set of error operators then it can correct all the errors in the set. So if the errors being considered are all possible combinations of the X matrix and the identity, we just need to find generators to correct a single X error per block of qubits (these are also the most likely errors to occur). </p>
<p>Here is an example, finding a way to overcome X errors by mapping one qubit into three. The spanning errors are $X\otimes\ I\otimes I$, which we shorten to $XII$; $IXI$ and $IIX$. X and Z anti-commute so we will use Z to create generators for the stabiliser. $g_1 =  ZZI$ and $g_2 = IZZ$ between them anti-commute each single-qubit error, making the stabilising group $\{III, ZZI, IZZ, ZIZ\}$. As the computational basis for the group we will select the eigenstates of Z as $|0\rangle$ and $|1\rangle$. This means that the set of vectors stabilised by the set include $|000\rangle$ and $|111\rangle$, which make an obvious choice for the encoding of the computational basis. Finally, computing the error syndromes gives this set of data:
<table>
<tr>
<th>Error</th><th>Syndrome</th></tr>
<tr><td>$III$</td><td>00</td></tr>
<tr><td>$XII$</td><td>10</td></tr>
<tr><td>$IXI$</td><td>11</td></tr>
<tr><td>$IIX$</td><td>01</td></tr>
<tr><td>$XXI$</td><td>10</td></tr>
<tr><td>$XIX$</td><td>11</td></tr>
<tr><td>$IXX$</td><td>01</td></tr>
<tr><td>$XXX$</td><td>00</td></tr>
</table>

<p>For each error syndrome, it is assumed that the error happened on one or no qubits. </p>
<p>A commonly used subclass of stabiliser codes are the Calderbank-Shor-Steane (CSS) codes, which use classical codes to create a code capable of detecting bit-flip and phase-flip errors. The process starts with 2 error correcting codes $C_1$ and $C_2$, with $C_2$ being a subset of $C_1$. This allows us to use the cosets of $C_2$ in $C_1$ to define the codewords. The encoded $|0\rangle$ will be the normalised sum of all the vectors in $C_2$, and each other codeword is similarly the normalised sum of all the vectors in one of the cosets. In particular, the coset for a codeword $c_i$ will be $(C_2 + c_i)$. After transmission through a channel, some of the summands of the codeword may have an error, represented by the addition of a 1 to the state or multiplication by a phase of (-1). 
$$\frac{1}{\sqrt{2^{k_2}}} )\sum_{x\in\ C_2}|x+c_i\ \rightarrow\rangle \rightarrow \frac{1}{\sqrt{2^{k_2}}}\sum_{x\in\ C_2}(-1)^{(c_i+x) e_p}  |x+c_i+e_b\rangle$$
Here, $k_2$ is the number of message bits that $C_2$ encodes. Luckily, the construction means these are easily correctable.</p>
<p>Firstly, each codeword in the sum is in $C_1$ so applying the parity check for $C_1$ will find a bit-flip error. Then a Hadamard gate is used to exchange $X$ and $Z$, so that bit-flip correction can be applied to the potential phase-flip error. By manipulating the sum a bit, it ends up in a form where each summand is in the dual code of $C_2$, which is the code with the parity check matrix for $C_2$ as a generating matrix. Using the dual code’s parity check matrix, errors are again located and can be corrected. Finally, the Hadamard gate is applied again to return to the original codeword. </p>
<p>One of the more widely-known CSS codes is the Steane code, which uses the Hamming [7,4] code and its dual as $C_1$ and $C_2$, resulting in a [7,1] code. The six generators need to anti-commute with both a single Z error and a single X error on each of the seven qubits:
<table>
<tr><th colspan ="2">X Generator</th><th colspan = "2">Z Generator</th></tr>
<tr><td>$g_1$</td><td>$IIIXXXX$</td><td>$g_4$</td><td>$IIIZZZZ$</td></tr>
<tr><td>$g_2$</td><td>$IXXIIXX$</td><td>$g_5$</td><td>$IZZIIZZ$</td></tr>
<tr><td>$g_3$</td><td>$XIXIXIX$</td><td>$g_6$</td><td>$ZIZIZIZ$</td></tr>
</table>
</p>
<p>
	<img src = "surface.png" class = "left" alt = "A diagram of the surface code">Another type of code which is commonly researched is the surface code, which uses an array of physical qubits as the encoding method. These are split between data and measurement qubits, with the measurement qubits further divided into X and Z. The action of the X measurement qubits is equivalent to measuring the  stabiliser XXXX on the surrounding data qubits, and ZZZZ for the Z measurement qubits. This results in each data qubit having 2 X and 2 Z operators applied to it (apart from some of those on the boundaries). The codes take advantage of the fact that a pair of X or Z operators won't cause the superpostion to collapse. Measuring the stabilisers also puts the system into a state which is an eigenstate of XXXX and ZZZZ simultaneously. </p>
	<p> The surface code operates by cycling paralell measurements: all the measurement qubits perform their operation at the same time to ensure the state of all the qubits is an eigenstate, and the combined state is referred to as the quiescent state. This remains the same after being "chosen"by the first code cycle which lets errors be detected. An error in a data qubit will affect the measurement of the adjacent X or Z qubits (or both), letting the type of error and location be determined. An error with a measurement will cause an error in a single measurement, which will usually disappear in the next cycle. 
</p>
</body>
</html>
